{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6959190d",
   "metadata": {},
   "source": [
    "### docTR + OpenAI API\n",
    "\n",
    "The moitve behind this project is when I saw my wife spent hours preparing exercice to our son. After diner, she seat at the couch with me and she started reading his textbook and prepare true/false and fill the blanks questions.\n",
    "\n",
    "So, why not automate this job? I tested ChatGPT giving a text and ask it to create 10 true/false and fill the blanks qustions. It showed me the result, and it was exactly what I wanted. The next step is to find a way to translate the textbook into a digitial format. Unfortunelty, we did not have the pdf of his textbook. So, the solutino is to take a picture and somehow translate into text file.\n",
    "\n",
    "That's where docTR comes in. docTR is an open soure Optical Character Recognition (OCR) that recognize words in an image and translate into a text format.\n",
    "\n",
    "Below is a simple proof of concept of this solution.\n",
    "\n",
    "Please not that this is an on-going project. I will improve the process based on our needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9c28e6",
   "metadata": {},
   "source": [
    "### Import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8266626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09139a8",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d4dbe164",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \".//images//\"\n",
    "OUTPUT_TEXT_FROM_IMAGE = \".//text_from_images//\"\n",
    "EXAM_QUESTIONS_DIR = \".//exam_questions//\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eb630d",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "19905bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(path=IMAGE_PATH, patter=\"*\"):\n",
    "    \"\"\"\n",
    "    Return a list with all files in the directory\n",
    "    Parameters:\n",
    "        path (string): the directory where the files are stored\n",
    "    \"\"\"\n",
    "    #files = sorted(os.walk(path))\n",
    "    files = glob.glob(path + patter)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7fd51bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(file_name, text_to_file, path=OUTPUT_TEXT_FROM_IMAGE, extension=\".txt\"):\n",
    "    file = open(path + file_name + extension, \"w\")\n",
    "    file.write(text_to_file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d7a51448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(text_json_format):\n",
    "    final_text = \"\"\n",
    "    for obj1 in text_json_format[\"pages\"][0][\"blocks\"]:\n",
    "        final_text += \" \\n \"\n",
    "        for obj2 in obj1[\"lines\"]:\n",
    "            #final_text += \" \\n \"\n",
    "            for obj3 in obj2[\"words\"]:\n",
    "                final_text += \" \" + obj3['value']\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "654e69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_exame(text, exam_type=\"True or False\", number_questions=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The text that ChatGPT will use to generate the exam.\n",
    "        exam_type (str): type of exam. It could be 'fill the blanks', 'true or False', 'multipe questions'\n",
    "    \"\"\"\n",
    "    #if (number_questions is not None):\n",
    "    #    number_question_text = f\"{number_questions}\"\n",
    "    system_msg = f\"You are a teacher specialized in history of Canada. \\\n",
    "                  I will send you a text regarding Canadian history, \\\n",
    "                  and I would like that you create an exam for a 10 years old kid \\\n",
    "                  The gola is to practice to his/her next exame at school. \\\n",
    "                  So, please generate from follwoing text, {number_questions} {exam_type} style exam: {text} \\\n",
    "                  Also provide the anwsers for each question at the and. \\\n",
    "                  \"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_msg \n",
    "        }\n",
    "    ]  \n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        messages = messages,\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        max_tokens = 500,\n",
    "    )\n",
    "    exam = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return exam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8885c",
   "metadata": {},
   "source": [
    "### Main flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1f2a3813",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\"../env.txt\")\n",
    "openai.api_key = config[\"OPENAI_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f74b1099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.//images/pag1_2.jpg', './/images/pag1_1.jpg']"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = get_images()\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4466a1d3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlacosta/Alberto/Pandas-Machine-Learning-Central/Projects/Question-Creator-School/env/lib/python3.11/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/Users/carlacosta/Alberto/Pandas-Machine-Learning-Central/Projects/Question-Creator-School/env/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Model instance\n",
    "# model = ocr_predictor(pretrained=True, detect_language=)\n",
    "model = ocr_predictor('db_resnet50', 'crnn_vgg16_bn', pretrained=True, assume_straight_pages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a149630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting the image file pag1_2.jpg...\n",
      "Converting the image file pag1_1.jpg...\n",
      "File pag1_1 created under .//text_from_images//\n"
     ]
    }
   ],
   "source": [
    "# loop for all images and generate the text file\n",
    "text = \"\"\n",
    "# get the base file name for the final file with all text combined\n",
    "text_file_name = os.path.basename(file_name).split(\".\")[0]\n",
    "for file_name in files:\n",
    "    print(f\"Converting the image file {os.path.basename(file_name)}...\")\n",
    "    document = DocumentFile.from_images(file_name)\n",
    "    result = model(document)\n",
    "    json_export = result.export()\n",
    "    text += extract_text(json_export)\n",
    "\n",
    "write_file(file_name=text_file_name, text_to_file=setattr(text)\n",
    "    \n",
    "print(f\"File '{text_file_name}' created under {OUTPUT_TEXT_FROM_IMAGE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ed6116ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the exam\n",
    "exam = generate_exame(text=text, exam_type=\"True or False\", number_questions=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "46756ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(file_name=\"exam_\"+text_file_name, path=EXAM_QUESTIONS_DIR, text_to_file=exam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ad9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ab058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b07665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
