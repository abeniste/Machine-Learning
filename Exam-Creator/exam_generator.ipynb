{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6959190d",
   "metadata": {},
   "source": [
    "# docTR + OpenAI API\n",
    "\n",
    "The moitve behind this project is when I saw my wife spent hours preparing exercice to our son. After diner, she seat on the couch with me and she started reading his textbook and prepare true/false and fill the blanks questions.\n",
    "\n",
    "So, why not automate this job? I tested ChatGPT giving a text and ask it to create 10 true/false and fill the blanks qustions. It showed me the result, and it was exactly what I wanted. The next step is to find a way to translate the textbook into a digitial format. Unfortunelty, we did not have the pdf of his textbook. So, the solution is to take a picture and use OCR to translate into a text file.\n",
    "\n",
    "docTR is an open soure Optical Character Recognition (OCR) that recognize words in an image and translate into a text format.\n",
    "\n",
    "Below is the solution.\n",
    "\n",
    "Please note that this is an on-going project. I will improve the process based on our needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9c28e6",
   "metadata": {},
   "source": [
    "### Import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8266626b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:weasyprint:Invalid or unsupported selector 'select:not(:has(option[selected])) option:first-of-type,\n",
      "option[selected]:not(option[selected] ~ option[selected]) ', ('Unknown pseudo-class', 'has')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models.predictor import OCRPredictor\n",
    "from doctr.models import recognition, db_resnet50\n",
    "from doctr.datasets import VOCABS, RecognitionDataset\n",
    "from doctr.models.detection.predictor import DetectionPredictor\n",
    "from doctr.models.recognition.predictor import RecognitionPredictor\n",
    "from doctr.models.preprocessor import PreProcessor\n",
    "\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09139a8",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4dbe164",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \".//images//\"\n",
    "OUTPUT_TEXT_FROM_IMAGE = \".//text_from_images//\"\n",
    "EXAM_QUESTIONS_DIR = \".//exam_questions//\"\n",
    "\n",
    "# Questions type\n",
    "TOTAL_QUESTION = 5\n",
    "FILL_BLANKS = [ \"fill the blanks\", \"fill_blanks\"]\n",
    "TRUE_FALSE = [\"true or false\", \"true_false\"]\n",
    "MULTIPLE_CHOICES = [\"multiple choices\", \"multiple_choices\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eb630d",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19905bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(path=IMAGE_PATH, patter=\"*\"):\n",
    "    \"\"\"\n",
    "    Return a list with all files in the directory\n",
    "    Parameters:\n",
    "        path (string): the directory where the files are stored\n",
    "    \"\"\"\n",
    "    #files = sorted(os.walk(path))\n",
    "    files = glob.glob(path + patter)\n",
    "    files = [f for f in files if os.path.isfile(f)]\n",
    "    \n",
    "    return sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd51bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(file_name, text_to_file, path=OUTPUT_TEXT_FROM_IMAGE, extension=\".txt\"):\n",
    "    file = open(path + file_name + extension, \"w\", encoding='utf-16')\n",
    "    file.write(text_to_file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32fbdfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_file(file, final_path=IMAGE_PATH + \"processed\"):\n",
    "    shutil.move(file, final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "654e69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_exam(text, exam_type=\"True or False\", number_questions=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The text that ChatGPT will use to generate the exam.\n",
    "        exam_type (str): type of exam. It could be 'fill the blanks', 'true or False', 'multipe questions'\n",
    "    \"\"\"\n",
    "    #if (number_questions is not None):\n",
    "    #    number_question_text = f\"{number_questions}\"\n",
    "    system_msg = f\"You are a teacher specialized in history of Canada. \\\n",
    "                  I will send you a text regarding Canadian history, \\\n",
    "                  and I would like that you create an exam for a 10 years old kid \\\n",
    "                  The goal is to practice for the next exame at school. \\\n",
    "                  So, please generate from follwoing exam with {number_questions} questions, {exam_type} style exam: {text} \\\n",
    "                  Also provide the anwsers for each question at the and. \\\n",
    "                  \"\n",
    "    # otherwise, the final answer will have weird characters.\n",
    "    #system_msg.encode(\"utf-8\").decode()\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_msg \n",
    "        }\n",
    "    ]  \n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        messages = messages,\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        max_tokens = 500,\n",
    "    )\n",
    "    exam = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return exam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8885c",
   "metadata": {},
   "source": [
    "## Main flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f2a3813",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\"../env.txt\")\n",
    "openai.api_key = config[\"OPENAI_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f74b1099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.//images/pag87.jpg', './/images/pag88.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = get_images()\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a77f63e",
   "metadata": {},
   "source": [
    "### Instanciate the model \n",
    "\n",
    "Instanciate the model for french language. Then go over the directory \"images\" and get all files. The logic assumes all files in the directory belongs to the same subject.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4466a1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlacosta/Alberto/Pandas-Machine-Learning-Central/Projects/Question-Creator-School/env/lib/python3.11/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/Users/carlacosta/Alberto/Pandas-Machine-Learning-Central/Projects/Question-Creator-School/env/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "## Model instance ##\n",
    "\n",
    "model = recognition.__dict__[\"crnn_mobilenet_v3_large\"](pretrained=True, vocab=VOCABS[\"french\"])\n",
    "predictor = RecognitionPredictor(PreProcessor((32, 128), preserve_aspect_ratio=True, batch_size=32, mean=(0.694, 0.695, 0.693), std=(0.299, 0.296, 0.301)), model)\n",
    "det_model = db_resnet50(pretrained=True)\n",
    "det_predictor = DetectionPredictor(PreProcessor((1280, 1280), batch_size=1, mean=(0.798, 0.785, 0.772), std=(0.264, 0.2749, 0.287)), det_model)\n",
    "\n",
    "# final predictor\n",
    "predictor = OCRPredictor(det_predictor, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a149630c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting the image file pag87.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlacosta/Alberto/Pandas-Machine-Learning-Central/Projects/Question-Creator-School/env/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting the image file pag88.jpg...\n",
      "File 'pag87' created under .//text_from_images//\n"
     ]
    }
   ],
   "source": [
    "## loop for all images and generate the text file ##\n",
    "\n",
    "# get the base file name for the final file with all text combined\n",
    "text_file_name = os.path.basename(files[0]).split(\".\")[0]\n",
    "\n",
    "text = \"\"\n",
    "for file_name in files:\n",
    "    print(f\"Converting the image file {os.path.basename(file_name)}...\")\n",
    "    document = DocumentFile.from_images(file_name)\n",
    "    result = predictor([document[0]])\n",
    "    text += result.render()\n",
    "    move_file(file_name)\n",
    "\n",
    "write_file(file_name=text_file_name, text_to_file=text)\n",
    "print(f\"File '{text_file_name}' created under {OUTPUT_TEXT_FROM_IMAGE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fadc144",
   "metadata": {},
   "source": [
    "### Generate the exam\n",
    "\n",
    "Generate three types of exams: fill the blanks, true/false and multiple choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e26fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the exams\n",
    "\n",
    "type_questions_list = [TRUE_FALSE, FILL_BLANKS, MULTIPLE_CHOICES]\n",
    "for question_type in type_questions_list:      \n",
    "    exam = generate_exam(text=text, exam_type=question_type[0], number_questions=TOTAL_QUESTION)\n",
    "    exam_file_name = \"exam_\" + text_file_name + \"_\" + question_type[1] + \".txt\"\n",
    "    write_file(file_name=exam_file_name, path=EXAM_QUESTIONS_DIR, text_to_file=exam)\n",
    "    print(f\"File '{exam_file_name}' created under {EXAM_QUESTIONS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6116ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ab058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7b07665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#plt.rcParams[\"figure.figsize\"] = [10.00, 20.00]\n",
    "#plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "#synthetic_pages = result.synthesize()\n",
    "#plt.imshow(synthetic_pages[0]); plt.axis('off'); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
